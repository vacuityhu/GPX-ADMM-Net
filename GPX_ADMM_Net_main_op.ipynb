{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import glob\n",
    "from time import time\n",
    "from PIL import Image\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python import debug as tf_debug\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "CS_ratio = 10    # 4, 10, 25, 30,, 40, 50\n",
    "\n",
    "if CS_ratio == 1:\n",
    "    m = 10\n",
    "elif CS_ratio == 10:\n",
    "    m = 109\n",
    "elif CS_ratio == 25:\n",
    "    m = 272\n",
    "elif CS_ratio == 40:\n",
    "    m = 436\n",
    "elif CS_ratio == 50:\n",
    "    m = 545\n",
    "\n",
    "block_size = 33\n",
    "n = block_size*block_size\n",
    "batch_size = 64\n",
    "nrtrain = 88912\n",
    "learning_rate = 0.0005\n",
    "\n",
    "EpochNum = 300\n",
    "layer = 41\n",
    "Training_data_Name = 'Training_Data_Img91.mat'\n",
    "Training_data = sio.loadmat(Training_data_Name)\n",
    "Training_labels = Training_data['labels']\n",
    "\n",
    "Test_Img = '../Test_Image'\n",
    "\n",
    "Phi_data_Name = 'phi_Folder/phi_0_%d_1089.mat' % CS_ratio\n",
    "Phi_data = sio.loadmat(Phi_data_Name)\n",
    "Phi_input = Phi_data['phi'].transpose()\n",
    "\n",
    "\n",
    "XX = Training_labels.transpose()\n",
    "YY = np.dot(Phi_input.transpose(), XX)\n",
    "YTY = np.dot(YY, YY.transpose())\n",
    "CCC = np.dot(XX, YY.transpose())\n",
    "Q_init = tf.constant(np.dot(CCC, np.linalg.inv(YTY)).transpose(), dtype=tf.float32)\n",
    "del XX, YY, YTY, CCC, Training_data\n",
    "\n",
    "X_input = tf.placeholder(tf.float32, [None, m])\n",
    "X_output = tf.placeholder(tf.float32, [None, n])\n",
    "X0 = tf.matmul(X_input, Q_init)\n",
    "Y = X_input\n",
    "\n",
    "\n",
    "def imread_CS_py(imgName):\n",
    "    block_size = 33\n",
    "    Iorg = np.array(Image.open(imgName), dtype='float32')\n",
    "    [row, col] = Iorg.shape\n",
    "    row_pad = block_size-np.mod(row,block_size)\n",
    "    col_pad = block_size-np.mod(col,block_size)\n",
    "    Ipad = np.concatenate((Iorg, np.zeros([row, col_pad])), axis=1)\n",
    "    Ipad = np.concatenate((Ipad, np.zeros([row_pad, col+col_pad])), axis=0)\n",
    "    [row_new, col_new] = Ipad.shape\n",
    "    return [Iorg, row, col, Ipad, row_new, col_new]\n",
    "\n",
    "def img2col_py(Ipad, block_size):\n",
    "    [row, col] = Ipad.shape\n",
    "    row_block = row/block_size\n",
    "    col_block = col/block_size\n",
    "    block_num = int(row_block*col_block)\n",
    "    img_col = np.zeros([block_size**2, block_num])\n",
    "    count = 0\n",
    "    for x in range(0, row-block_size+1, block_size):\n",
    "        for y in range(0, col-block_size+1, block_size):\n",
    "            img_col[:, count] = Ipad[x:x+block_size, y:y+block_size].reshape([-1])\n",
    "            count = count + 1\n",
    "    return img_col\n",
    "\n",
    "def col2im_CS_py(X_col, row, col, row_new, col_new):\n",
    "    block_size = 33\n",
    "    X0_rec = np.zeros([row_new, col_new])\n",
    "    count = 0\n",
    "    for x in range(0, row_new-block_size+1, block_size):\n",
    "        for y in range(0, col_new-block_size+1, block_size):\n",
    "            X0_rec[x:x+block_size, y:y+block_size] = X_col[:, count].reshape([block_size, block_size])\n",
    "            count = count + 1\n",
    "    X_rec = X0_rec[:row, :col]\n",
    "    return X_rec\n",
    "\n",
    "def psnr(img1, img2):\n",
    "    img1.astype(np.float32)\n",
    "    img2.astype(np.float32)\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "filepaths = glob.glob(Test_Img + '/*.tif')\n",
    "ImgNum = len(filepaths)\n",
    "PSNR_All = np.zeros([1, ImgNum], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softshrink(x, lambd):\n",
    "    return tf.nn.relu(x - lambd) - tf.nn.relu(-1*x - lambd)\n",
    "\n",
    "def conv_dict(Input, weight1, weight2):\n",
    "    Output = tf.nn.conv2d(Input, weight1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    Output = tf.nn.relu(Output)\n",
    "    Output = tf.nn.conv2d(Output, weight2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return Output\n",
    "\n",
    "def truncate(Input, weights, index):\n",
    "    Input = tf.reshape(Input, shape=[-1, block_size, block_size, 1])\n",
    "    dict_output = conv_dict(Input, weights['filter_1%d' %(index)], weights['filter_2%d' %(index)])\n",
    "    shrink_output = softshrink( dict_output, weights['Lambda_%d' %(index)]  )\n",
    "    final_output = conv_dict( shrink_output - dict_output, weights['filter_5%d' %(index)], weights['filter_6%d' %(index)])\n",
    "    final_output = tf.reshape(final_output, shape=[-1, n])\n",
    "    return final_output\n",
    "\n",
    "def sym_op(Input, weights, index):\n",
    "    Input = tf.reshape(Input, shape=[-1, block_size, block_size, 1])\n",
    "    Output = conv_dict(Input, weights['filter_1%d' %(index)], weights['filter_2%d' %(index)])\n",
    "    Output = conv_dict(Output, weights['filter_5%d' %(index)], weights['filter_6%d' %(index)])\n",
    "    return Output - Input\n",
    "\n",
    "\n",
    "def forwarding(Y, weights, layer):\n",
    "    sym = []\n",
    "    sol_set = []\n",
    "    Y_Phi_T_G = tf.matmul(Y, Phi_T_G)\n",
    "    X = X0\n",
    "    M = tf.zeros_like(X)\n",
    "    for i in range(layer-1):\n",
    "        Z = tf.matmul(X, FC_X) + tf.matmul(M, FC_M(weights['Beta1_%d' %(i)])) + 10*Y_Phi_T_G\n",
    "        X = Z + weights['Beta2_%d' %(i)]*truncate(Z, weights, i)\n",
    "        M = weights['Beta3_%d' %(i)]*(Z - X)\n",
    "        sym.append( sym_op(Z, weights, i) )\n",
    "        sol_set.append(X)\n",
    "    Z = tf.matmul(X, FC_X) + tf.matmul(M, FC_M(weights['Beta1_%d' %(layer-1)])) + 10*Y_Phi_T_G\n",
    "    X = Z + weights['Beta2_%d' %(layer-1)]*truncate(Z, weights, layer-1)\n",
    "    sym.append( sym_op(Z, weights, layer-1) )\n",
    "    sol_set.append(X)\n",
    "        \n",
    "    return [sol_set, sym]\n",
    "\n",
    "weights = {}\n",
    "Phi_T_input = Phi_input.transpose()\n",
    "PhiT_Phi = np.matmul(Phi_input, Phi_T_input).transpose()\n",
    "g = np.transpose(np.linalg.inv(10*PhiT_Phi + 0.1*np.eye(n)))\n",
    "Phi_T_G = tf.constant(np.matmul(Phi_T_input, g), dtype=tf.float32)\n",
    "G = tf.constant(g, dtype=tf.float32)\n",
    "FC_X = 0.1*G\n",
    "def FC_M(beta):\n",
    "    return (1/beta)*tf.eye(n) - G\n",
    "\n",
    "for i in range(layer):\n",
    "    temp = \"filter_1%d\" % (i)\n",
    "    weights[temp] = tf.get_variable(shape=[3,3, 1,32], initializer=tf.contrib.layers.xavier_initializer_conv2d(), name=\"filter_1%d\" % (i))\n",
    "    temp = \"filter_2%d\" % (i)\n",
    "    weights[temp] = tf.get_variable(shape=[3,3,32,32], initializer=tf.contrib.layers.xavier_initializer_conv2d(), name=\"filter_2%d\" % (i))\n",
    "    temp = \"filter_5%d\" % (i)\n",
    "    weights[temp] = tf.get_variable(shape=[3,3,32,32], initializer=tf.contrib.layers.xavier_initializer_conv2d(), name=\"filter_5%d\" % (i))\n",
    "    temp = \"filter_6%d\" % (i)\n",
    "    weights[temp] = tf.get_variable(shape=[3,3,32, 1], initializer=tf.contrib.layers.xavier_initializer_conv2d(), name=\"filter_6%d\" % (i))\n",
    "    temp = \"Lambda_%d\" % (i)\n",
    "    weights[temp] = tf.Variable(0.02, name=\"Lambda_%d\" % (i))\n",
    "    temp = \"Beta1_%d\" % (i)\n",
    "    weights[temp] = tf.Variable(0.3, name=\"Beta1_%d\" % (i))\n",
    "    temp = \"Beta2_%d\" % (i)\n",
    "    weights[temp] = tf.Variable((2.0-(1.5*i/layer)), name=\"Beta2_%d\" % (i))\n",
    "for i in range(layer-1):\n",
    "    temp = \"Beta3_%d\" % (i)\n",
    "    weights[temp] = tf.Variable(0.2, name=\"Beta3_%d\" % (i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=1)\n",
    "\n",
    "model_dir = 'Layer_%d_ratio_0_%d_ADMM_Net_Model' % (layer, CS_ratio)\n",
    "output_file_name = \"Log_output_%s.txt\" % (model_dir)\n",
    "\n",
    "result, sym = forwarding(Y, weights, layer)\n",
    "loss_MSE = 0\n",
    "for k in range(len(result)):\n",
    "    loss_MSE += tf.reduce_mean(tf.square(result[k] - X_output))\n",
    "loss_sym = 0\n",
    "for k in range(len(sym)):\n",
    "    loss_sym += tf.reduce_mean(tf.square(sym[k]))\n",
    "\n",
    "loss_op =  loss_MSE + 0.01*loss_sym\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Layer = %d, ratio = %d, training start:\" % (layer, CS_ratio))\n",
    "min_loss = 1\n",
    "rec_PSNR = 0\n",
    "for epoch_i in range(0, EpochNum+1):\n",
    "    start = time()\n",
    "    randidx_all = np.random.permutation(nrtrain)\n",
    "    for batch_i in range(nrtrain // batch_size):\n",
    "        randidx = randidx_all[batch_i*batch_size:(batch_i+1)*batch_size]\n",
    "        batch_ys = Training_labels[randidx, :]\n",
    "        batch_xs = np.matmul(batch_ys, Phi_input)\n",
    "        feed_dict={X_input: batch_xs, X_output: batch_ys}\n",
    "        _ = sess.run(optimizer, feed_dict=feed_dict)\n",
    "       \n",
    "    avg_PSNR = 0\n",
    "    for img_no in range(ImgNum):\n",
    "        imgName = filepaths[img_no]\n",
    "        [Iorg, row, col, Ipad, row_new, col_new] = imread_CS_py(imgName)\n",
    "        Icol = img2col_py(Ipad, block_size).transpose() /255.0\n",
    "        Img_input = np.matmul(Icol, Phi_input)\n",
    "        Prediction_value = sess.run(result[-1], feed_dict={X_input: Img_input})\n",
    "        X_rec = col2im_CS_py(Prediction_value.transpose(), row, col, row_new, col_new)\n",
    "        X_rec = np.clip(X_rec * 255, 0, 255, out = X_rec)\n",
    "        avg_PSNR = avg_PSNR + psnr(Iorg, X_rec)\n",
    "    avg_PSNR = avg_PSNR/11\n",
    "    val_rec_PSNR = avg_PSNR\n",
    "    output_data = \"AVG PSNR is %.2f\" % (avg_PSNR)\n",
    "    print(output_data)\n",
    "    if val_rec_PSNR > rec_PSNR:\n",
    "        rec_PSNR = val_rec_PSNR\n",
    "        saver.save(sess,'ckpt/%s/Saved_Model.cpkt' % (model_dir), global_step=epoch_i)\n",
    "    end = time()\n",
    "    print(\"Time cost %.2f\" %(end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = tf.train.latest_checkpoint( 'ckpt/%s/' % (model_dir) )\n",
    "saver.restore(sess, model_file)\n",
    "avg_PSNR = 0\n",
    "avg_SSIM = 0\n",
    "avg_running_time = 0\n",
    "\n",
    "print(\"Layer = %d, ratio = %d, testing start:\" % (layer, CS_ratio))\n",
    "for img_no in range(ImgNum):\n",
    "    imgName = filepaths[img_no]\n",
    "    [Iorg, row, col, Ipad, row_new, col_new] = imread_CS_py(imgName)\n",
    "    Icol = img2col_py(Ipad, block_size).transpose() /255.0\n",
    "    Img_input = np.matmul(Icol, Phi_input)\n",
    "    start = time()\n",
    "    Prediction_value = sess.run(result[-1], feed_dict={X_input: Img_input})\n",
    "    end = time()\n",
    "    X_rec = col2im_CS_py(Prediction_value.transpose(), row, col, row_new, col_new)\n",
    "    X_rec = np.clip(X_rec * 255, 0, 255, out = X_rec)\n",
    "    rec_PSNR = psnr(Iorg, X_rec)\n",
    "    temp = Iorg.shape\n",
    "    rec_SSIM = sess.run(tf.image.ssim(tf.image.convert_image_dtype(tf.reshape(X_rec, shape=list(temp) + [1]), tf.float32), tf.reshape(Iorg, shape=list(temp) + [1]), max_val=255.0))\n",
    "    output_data = \"%s PSNR is %.2f, SSIM is %.2f, Run time is %.4f\" % (imgName, rec_PSNR, rec_SSIM, (end - start) )\n",
    "    print(output_data)\n",
    "    img_rec_name = \"%s_rec_PSNR_%.2f.png\" % (imgName, rec_PSNR)\n",
    "    x_im_rec = Image.fromarray(np.clip(X_rec * 255, 0, 255).astype(np.uint8))\n",
    "    x_im_rec.save(img_rec_name)\n",
    "\n",
    "    avg_running_time = avg_running_time + (end - start)\n",
    "    avg_PSNR = avg_PSNR + rec_PSNR\n",
    "    avg_SSIM = avg_SSIM + rec_SSIM\n",
    "avg_PSNR = avg_PSNR/11\n",
    "avg_SSIM = avg_SSIM/11\n",
    "avg_running_time = avg_running_time/17\n",
    "print(\"SET11 AVG PSNR is %.2f, AVG SSIM is %.2f, AVG running time is %.2f\" % (avg_PSNR, avg_SSIM, avg_running_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
